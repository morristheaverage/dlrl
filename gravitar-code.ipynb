{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "gravitar.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTNU1mwGB1ZD"
      },
      "source": [
        "**Initialise**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TZefME0MTvA"
      },
      "source": [
        "# This is a DreamerV2 implementation including replay memory and a target network \n",
        "# The model uses a RAM environment, converting bytes to 8 bit values. It shows very\n",
        "# little tendency for exploration, preferring to shoot the alien that appears in the\n",
        "# initial stage, rather than visiting planets.\n",
        "# The code is loosely based on https://github.com/danijar/dreamerv2, which is released under the MIT licesne,\n",
        "# however the implementation is largely done from scratch\n",
        "# because the github implementation is written in tensorflow. It was, however, somewhat useful.\n",
        "\n",
        "\n",
        "# imports\n",
        "import gym\n",
        "import collections\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.distributions as td\n",
        "\n",
        "# hyperparameters\n",
        "init_episodes     = 5\n",
        "learning_rate     = 0.0005\n",
        "gamma             = 0.995\n",
        "lambda_hp         = 0.95\n",
        "buffer_limit      = 50000\n",
        "batch_size        = 50\n",
        "video_every       = 5\n",
        "print_every       = 1\n",
        "horizon           = 15\n",
        "latent_categories = 16\n",
        "hidden_size       = 100\n",
        "\n",
        "seq_len           = 50\n",
        "\n",
        "\n",
        "class ReplayBuffer():\n",
        "    def __init__(self):\n",
        "        self.buffer = collections.deque(maxlen=buffer_limit)\n",
        "    \n",
        "    def put(self, transition):\n",
        "        self.buffer.append(transition)\n",
        "    \n",
        "    def sample(self, n, l):\n",
        "        start_points = [random.randint(0, len(self.buffer)) for _ in range(n)]\n",
        "        mini_batch = random.sample(self.buffer, n)\n",
        "        h_lst, xs_lst, as_lst, rs_lst, done_mask_lst = [], [], [], [], []\n",
        "        \n",
        "        for start in start_points:\n",
        "            # Place start at start of the list\n",
        "            self.buffer.rotate(-start)\n",
        "            h, x, a, r, done_mask = self.buffer[0]\n",
        "            h_lst.append(h)\n",
        "            xs_lst.append(x.clone().detach())\n",
        "            as_lst.append(a.clone().detach())\n",
        "            rs_lst.append(r.clone().detach())\n",
        "            done_mask_lst.append([done_mask])\n",
        "            self.buffer.rotate(-1)\n",
        "            for _, data in zip(range(l-1), self.buffer):\n",
        "                _, x, a, r, done_mask = self.buffer[0]\n",
        "                xs_lst[-1] = torch.cat((xs_lst[-1], x), dim=0)\n",
        "                as_lst[-1] = torch.cat((as_lst[-1], a), dim=0)\n",
        "                rs_lst[-1] = torch.cat((rs_lst[-1], r), dim=0)\n",
        "                done_mask_lst[-1].append([done_mask])\n",
        "            \n",
        "            self.buffer.rotate(start+1)\n",
        "\n",
        "        # return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
        "        #        torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch.float), \\\n",
        "        #        torch.tensor(done_mask_lst)\n",
        "        return h_lst, xs_lst, as_lst, rs_lst, done_mask_lst\n",
        "    \n",
        "    def size(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "class QNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(np.array(env.observation_space.shape).prod(), 256)\n",
        "        self.fc2 = nn.Linear(256, 84)\n",
        "        self.fc3 = nn.Linear(84, env.action_space.n)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0),-1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "      \n",
        "    def sample_action(self, obs, epsilon):\n",
        "        out = self.forward(obs)\n",
        "        coin = random.random()\n",
        "        if coin < epsilon:\n",
        "            return random.randint(16, 17)\n",
        "        else : \n",
        "            return out.argmax().item()\n",
        "\n",
        "class WorldModel(nn.Module):\n",
        "    def __init__(self, f=latent_categories):\n",
        "        super(WorldModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.f = f\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=f*f + env.action_space.n,\n",
        "            hidden_size=self.hidden_size\n",
        "            )\n",
        "        self.enc_layers = nn.Sequential(\n",
        "            nn.Linear(1024 + self.hidden_size, 512),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(512, f*f),\n",
        "            nn.Unflatten(1, (f, f)),\n",
        "            nn.Softmax(dim=2)   # log likelihood or probabilities?\n",
        "        )\n",
        "        self.dec_layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(f*f + self.hidden_size, 512),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.transition_pred = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size, 512),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(512, f*f),\n",
        "            nn.Unflatten(1, (f, f)),\n",
        "            nn.Softmax(dim=2)   # log likelihood or probabilities?\n",
        "        )\n",
        "\n",
        "        self.reward_pred = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size + f*f, 50),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(50, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def ste(self, fn, x):\n",
        "        dis = fn(probs=x)\n",
        "        sample = dis.sample()\n",
        "        # Add grad\n",
        "        sample = sample + x - x.detach()\n",
        "        return sample\n",
        "    \n",
        "    def encode(self, x, h):\n",
        "        x = torch.cat((x, h), dim=1)\n",
        "        x = self.enc_layers(x)\n",
        "        return self.ste(td.OneHotCategorical, x)\n",
        "    \n",
        "    def decode(self, z, h):\n",
        "        z = torch.cat((z, h), dim=1)\n",
        "        return self.dec_layers(z)\n",
        "    \n",
        "    def forward(self, htm1, x_seq, a_seq):\n",
        "        z_probs, z_hat_probs, x_hat_seq, r_hat_probs = [], [], [], []\n",
        "        z_seq = []\n",
        "\n",
        "        try:\n",
        "            bs = htm1.size(1)\n",
        "        except:\n",
        "            bs = batch_size\n",
        "\n",
        "\n",
        "        for x, a in zip(x_seq, a_seq):\n",
        "            if htm1 is None:\n",
        "                htm1 = torch.zeros(1, bs, self.hidden_size).to(device)\n",
        "                h = htm1.view(bs, -1)\n",
        "                # Encode a sequence of states\n",
        "                z_prob = self.encode(x, h)\n",
        "                z_hat_prob = z_prob.clone().detach()\n",
        "                z = self.ste(td.OneHotCategorical, z_prob)\n",
        "            else:\n",
        "                h = htm1.view(bs, -1)\n",
        "                z_hat_prob = self.transition_pred(h)\n",
        "                z_prob = self.encode(x, h)\n",
        "                z = self.ste(td.OneHotCategorical, z_prob)\n",
        "            # print(z.shape)\n",
        "            z = z.view(bs, self.f*self.f)\n",
        "            # Decode latent representation\n",
        "            x_hat = self.decode(z, h)\n",
        "            r_hat = self.reward_pred(torch.cat((z, h), dim=1))\n",
        "\n",
        "            rnn_input = torch.cat((z.view(1, bs, -1), a.view(1, bs, -1)), dim=2)\n",
        "            _, htm1 = self.gru(rnn_input, htm1)\n",
        "            \n",
        "            z_seq.append(z)\n",
        "            x_hat_seq.append(x_hat)\n",
        "            r_hat_probs.append(r_hat)\n",
        "            z_probs.append(z_prob)\n",
        "            z_hat_probs.append(z_hat_prob)\n",
        "\n",
        "        return htm1, z_seq, x_hat_seq, r_hat_probs, z_probs, z_hat_probs\n",
        "\n",
        "class Actor(nn.Module):\n",
        "    def __init__(self, f=latent_categories):\n",
        "        super(Actor, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(f*f, 100),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(100, env.action_space.n),\n",
        "            nn.LogSoftmax(dim=-1)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class Critic(nn.Module):\n",
        "    def __init__(self, f=latent_categories):\n",
        "        super(Critic, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(f*f, 100),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(100, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "            \n",
        "def train(q, q_target, memory, optimizer):\n",
        "    for i in range(10):\n",
        "        s,a,r,s_prime,done_mask = memory.sample(batch_size)\n",
        "\n",
        "        q_out = q(s)\n",
        "        q_a = q_out.gather(1,a)\n",
        "        max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n",
        "        target = r + gamma * max_q_prime * done_mask\n",
        "        loss = F.smooth_l1_loss(q_a, target)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X77nwuGNDoQt"
      },
      "source": [
        "def train_wm(model, memory, optimizer):\r\n",
        "    model.zero_grad()\r\n",
        "\r\n",
        "    h_lst, xs_lst, as_lst, rs_lst, done_mask_lst = memory.sample(batch_size, seq_len)\r\n",
        "    h = torch.cat([h for h in h_lst], dim=1)\r\n",
        "    x = torch.cat([x for x in xs_lst], dim=1)\r\n",
        "    a = torch.cat([a for a in as_lst], dim=1)\r\n",
        "    r = torch.cat([r for r in rs_lst], dim=1)\r\n",
        "    \r\n",
        "    # Run through model\r\n",
        "    _, z_seq, x_hat_seq, r_hat_seq, z_probs, z_hat_probs = wm(h, x, a)\r\n",
        "\r\n",
        "    try:\r\n",
        "        print(\"initial loss:\", total_loss)\r\n",
        "    except:\r\n",
        "        pass\r\n",
        "\r\n",
        "    # Calculate how well model did\r\n",
        "    x_hat = torch.cat([x.view(1, x.size(0), -1) for x in x_hat_seq], dim=0)\r\n",
        "    recon_loss = bce(x_hat, x)\r\n",
        "    r_hat = torch.cat([r.view(1, x.size(0)) for r in r_hat_seq], dim=0)\r\n",
        "    reward_loss = mse(r_hat, r)\r\n",
        "\r\n",
        "    z_hat = torch.cat([z.view(1, x.size(0), -1) for z in z_hat_probs], dim=0)\r\n",
        "    z = torch.cat([z.view(1, x.size(0), -1) for z in z_seq], dim=0).detach()\r\n",
        "    z_prob = torch.cat([z.view(1, x.size(0), -1) for z in z_probs], dim=0)\r\n",
        "    trans_loss = 0.08 * bce(z_hat, z)\r\n",
        "    ent_reg    = -0.02 * bce(z_prob, z)\r\n",
        "    \r\n",
        "    total_loss = recon_loss + reward_loss + trans_loss + ent_reg\r\n",
        "    # print(\"total loss:\", recon_loss, \"+\", reward_loss, \"+\", trans_loss, \"+\", ent_reg, \"=\", total_loss)\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "    total_loss.backward()\r\n",
        "    optimizer.step()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyqeZTX1sGGz"
      },
      "source": [
        "def dream(memory, wm, actor, critic, critic_target, optimizer_a, optimizer_c):\r\n",
        "    h_lst, xs_lst, _, _, _ = memory.sample(batch_size, horizon)\r\n",
        "    h = torch.cat([h for h in h_lst], dim=1).view(1, batch_size, -1)\r\n",
        "    x = torch.cat([x[0].view(1, 1, -1) for x in xs_lst], dim=1).view(batch_size, -1)\r\n",
        "\r\n",
        "    z = wm.encode(x, h.view(batch_size, -1)).detach()\r\n",
        "    r_lst = []      # Actual rewards\r\n",
        "    v_lst = []      # Estimate of long term value\r\n",
        "    v_targets = []  # Likewise\r\n",
        "\r\n",
        "    act_lls = []\r\n",
        "\r\n",
        "    # Imagine up to horizon\r\n",
        "    for i in range(horizon):\r\n",
        "        # Take an action\r\n",
        "        a = actor(z)\r\n",
        "        act_lls.append(a)\r\n",
        "        r_lst.append(wm.reward_pred(torch.cat((z.view(1, batch_size, -1), h), dim=2).view(batch_size, -1)).detach())\r\n",
        "\r\n",
        "        # Feed into simulator\r\n",
        "        rnn_input = torch.cat((z.view(1, batch_size, -1), torch.exp(a).view(1, batch_size, -1)), dim=2)\r\n",
        "        _, h = wm.gru(rnn_input, h)\r\n",
        "        z = wm.transition_pred(h.view(batch_size, -1)).detach()\r\n",
        "\r\n",
        "        # Check rewards\r\n",
        "        v_lst.append(critic(z))\r\n",
        "        v_targets.append(critic_target(z).detach())\r\n",
        "    \r\n",
        "    # print(r_lst)\r\n",
        "    V = [r_lst[-1] + gamma*v_targets[-1]]\r\n",
        "    r_lst = reversed(r_lst[:-1])\r\n",
        "    v_targets = reversed(v_targets[:-1])\r\n",
        "\r\n",
        "    for r, v_target in zip(r_lst, v_targets):\r\n",
        "        V.append(r + gamma*(1-lambda_hp)*v_target + lambda_hp*V[-1])\r\n",
        "    \r\n",
        "    critic_loss = sum([mse(v_est, v_tar) for v_est, v_tar in zip(v_lst, reversed(V))]) / horizon / 2.0\r\n",
        "    optimizer_c.zero_grad()\r\n",
        "    critic_loss.backward()\r\n",
        "    optimizer_c.step()\r\n",
        "\r\n",
        "    actor_loss = sum(sum(loss_t for loss_t in [-sum(act_ll*(V_t - v_t.detach())) for act_ll, v_t, V_t in zip(act_lls, v_lst, reversed(V))])) / env.action_space.n / batch_size / (horizon - 1)\r\n",
        "    optimizer_a.zero_grad()\r\n",
        "    actor_loss.backward()\r\n",
        "    optimizer_a.step()\r\n",
        "    \r\n",
        "        "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ck-chjFdScJ"
      },
      "source": [
        "**Train**\n",
        "\n",
        "← You can download the videos from the videos folder in the files on the left"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv1QhDbliMv5",
        "outputId": "e2541bea-d144-4ea6-f008-f7375da0ebf1"
      },
      "source": [
        "# setup the Gravitar ram environment, and record a video every 50 episodes. You can use the non-ram version here if you prefer\r\n",
        "env = gym.make('Gravitar-ram-v0')\r\n",
        "env = gym.wrappers.Monitor(env, \"./video\", video_callable=lambda episode_id: (episode_id%video_every)==0,force=True)\r\n",
        "\r\n",
        "# reproducible environment and action spaces, do not change lines 6-11 here (tools > settings > editor > show line numbers)\r\n",
        "seed = 742\r\n",
        "torch.manual_seed(seed)\r\n",
        "env.seed(seed)\r\n",
        "random.seed(seed)\r\n",
        "np.random.seed(seed)\r\n",
        "env.action_space.seed(seed)\r\n",
        "\r\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "cpu = torch.device('cpu')\r\n",
        "\r\n",
        "wm = WorldModel()\r\n",
        "actor = Actor()\r\n",
        "critic = Critic().to(device)\r\n",
        "critic_target = Critic().to(device)\r\n",
        "critic_target.load_state_dict(critic.state_dict())\r\n",
        "memory = ReplayBuffer()\r\n",
        "\r\n",
        "score    = 0.0\r\n",
        "marking  = []\r\n",
        "optimizer_wm = optim.Adam(wm.parameters(), lr=learning_rate)\r\n",
        "optimizer_a = optim.Adam(actor.parameters(), lr=learning_rate)\r\n",
        "optimizer_c = optim.Adam(critic.parameters(), lr=learning_rate)\r\n",
        "\r\n",
        "bce = nn.BCELoss()\r\n",
        "mse = nn.MSELoss()\r\n",
        "\r\n",
        "for _ in range(init_episodes):\r\n",
        "    done = False\r\n",
        "    h = torch.zeros(1, 1, hidden_size)\r\n",
        "    x = torch.from_numpy(np.unpackbits(env.reset())).float().view(1, 1, 1024)\r\n",
        "    while not done:\r\n",
        "        a = random.randint(0, env.action_space.n-1)\r\n",
        "        x_prime, r, done, _ = env.step(a)\r\n",
        "        a = F.one_hot(torch.LongTensor([[a]]), num_classes=env.action_space.n).float()\r\n",
        "        memory.put((h.to(device), x.to(device), a.to(device), torch.tensor([[r/100.0]]).to(device), done))\r\n",
        "        h, _, _, _, _, _ = wm(h, x, a)\r\n",
        "        h = h.detach()\r\n",
        "        x = torch.from_numpy(np.unpackbits(x_prime)).float().view(1, 1, 1024)\r\n",
        "        \r\n",
        "print(memory.size())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5stHkFq4UztI",
        "outputId": "fbf6f5c1-4dba-4a76-d807-7898dfbd77e8"
      },
      "source": [
        "env = gym.make('Gravitar-ram-v0')\n",
        "env = gym.wrappers.Monitor(env, \"./video\", video_callable=lambda episode_id: (episode_id%video_every)==0,force=True)\n",
        "for n_episode in range(int(1e32)):\n",
        "    epsilon = max(0.01, 0.08 - 0.01*(n_episode/200)) # linear annealing from 8% to 1%\n",
        "    wm = wm.to(device)\n",
        "    actor = actor.to(device)\n",
        "    for _ in range(20):\n",
        "        # Dynamics learning\n",
        "        train_wm(wm, memory, optimizer_wm)\n",
        "\n",
        "        # Behaviour learning\n",
        "        dream(memory, wm, actor, critic, critic_target, optimizer_a, optimizer_c)\n",
        "    critic_target.load_state_dict(critic.state_dict())\n",
        "\n",
        "    # Do a run\n",
        "    wm = wm.to(cpu)\n",
        "    actor = actor.to(cpu)\n",
        "    print(\"brrr\")\n",
        "    x = torch.from_numpy(np.unpackbits(env.reset())).float().view(1, 1, 1024)\n",
        "    h = torch.zeros(1, 1, hidden_size)\n",
        "    done = False\n",
        "    score = 0.0\n",
        "    while not done:\n",
        "        z = wm.encode(x.view(1, -1), h.view(1, -1))\n",
        "        act_dis = td.Categorical(logits=actor(z))\n",
        "        if random.random() < epsilon:\n",
        "            a = random.randint(0, env.action_space.n-1)\n",
        "        else:\n",
        "            a = act_dis.sample()\n",
        "        x_prime, r, done, info = env.step(a)\n",
        "        a = F.one_hot(torch.LongTensor([[a]]), num_classes=env.action_space.n).float()\n",
        "        memory.put((h.to(device), x.to(device), a.to(device), torch.tensor([[r/100.0]]).to(device), done))\n",
        "        h, _, _, _, _, _ = wm(h, x, a)\n",
        "        h = h.detach()\n",
        "        x = torch.from_numpy(np.unpackbits(x_prime)).float().view(1, 1, 1024)\n",
        "\n",
        "        score += r\n",
        "\n",
        "    # do not change lines 44-48 here, they are for marking the submission log\n",
        "    marking.append(score)\n",
        "    if n_episode%100 == 0:\n",
        "        print(\"marking, episode: {}, score: {:.1f}, mean_score: {:.2f}, std_score: {:.2f}\".format(\n",
        "            n_episode, score, np.array(marking).mean(), np.array(marking).std()))\n",
        "        marking = []\n",
        "\n",
        "        \n",
        "\n",
        "    # you can change this part, and print any data you like (so long as it doesn't start with \"marking\")\n",
        "    if n_episode%print_every==0 and n_episode!=0:\n",
        "        print(\"episode: {}, score: {:.1f}, epsilon: {:.2f}\".format(n_episode, score, epsilon))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "brrr\n",
            "marking, episode: 0, score: 250.0, mean_score: 250.00, std_score: 0.00\n",
            "brrr\n",
            "episode: 1, score: 200.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 2, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 3, score: 350.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 4, score: 350.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 5, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 6, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 7, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 8, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 9, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 10, score: 550.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 11, score: 500.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 12, score: 450.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 13, score: 250.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 14, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 15, score: 450.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 16, score: 200.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 17, score: 500.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 18, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 19, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 20, score: 350.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 21, score: 100.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 22, score: 250.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 23, score: 600.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 24, score: 250.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 25, score: 250.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 26, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 27, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 28, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 29, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 30, score: 250.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 31, score: 500.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 32, score: 250.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 33, score: 250.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 34, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 35, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 36, score: 200.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 37, score: 100.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 38, score: 500.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 39, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 40, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 41, score: 450.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 42, score: 100.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 43, score: 100.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 44, score: 450.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 45, score: 100.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 46, score: 350.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 47, score: 250.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 48, score: 100.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 49, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 50, score: 350.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 51, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 52, score: 100.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 53, score: 250.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 54, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 55, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 56, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 57, score: 450.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 58, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 59, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 60, score: 500.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 61, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 62, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 63, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 64, score: 100.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 65, score: 250.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 66, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 67, score: 100.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 68, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 69, score: 100.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 70, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 71, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 72, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 73, score: 200.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 74, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 75, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 76, score: 200.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 77, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 78, score: 350.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 79, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 80, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 81, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 82, score: 250.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 83, score: 350.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 84, score: 100.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 85, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 86, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 87, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 88, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 89, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 90, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 91, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 92, score: 250.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 93, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 94, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 95, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 96, score: 200.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 97, score: 0.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 98, score: 100.0, epsilon: 0.08\n",
            "brrr\n",
            "episode: 99, score: 250.0, epsilon: 0.08\n",
            "brrr\n",
            "marking, episode: 100, score: 0.0, mean_score: 140.00, std_score: 173.06\n",
            "episode: 100, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 101, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 102, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 103, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 104, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 105, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 106, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 107, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 108, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 109, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 110, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 111, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 112, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 113, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 114, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 115, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 116, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 117, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 118, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 119, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 120, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 121, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 122, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 123, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 124, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 125, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 126, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 127, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 128, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 129, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 130, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 131, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 132, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 133, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 134, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 135, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 136, score: 350.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 137, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 138, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 139, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 140, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 141, score: 300.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 142, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 143, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 144, score: 350.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 145, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 146, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 147, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 148, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 149, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 150, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 151, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 152, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 153, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 154, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 155, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 156, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 157, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 158, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 159, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 160, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 161, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 162, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 163, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 164, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 165, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 166, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 167, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 168, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 169, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 170, score: 750.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 171, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 172, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 173, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 174, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 175, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 176, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 177, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 178, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 179, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 180, score: 350.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 181, score: 400.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 182, score: 350.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 183, score: 350.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 184, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 185, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 186, score: 450.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 187, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 188, score: 300.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 189, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 190, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 191, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 192, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 193, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 194, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 195, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 196, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 197, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 198, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 199, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "marking, episode: 200, score: 700.0, mean_score: 110.50, std_score: 138.80\n",
            "episode: 200, score: 700.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 201, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 202, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 203, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 204, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 205, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 206, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 207, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 208, score: 350.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 209, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 210, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 211, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 212, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 213, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 214, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 215, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 216, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 217, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 218, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 219, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 220, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 221, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 222, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 223, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 224, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 225, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 226, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 227, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 228, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 229, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 230, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 231, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 232, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 233, score: 250.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 234, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 235, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 236, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 237, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 238, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 239, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 240, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 241, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 242, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 243, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 244, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 245, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 246, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 247, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 248, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 249, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 250, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 251, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 252, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 253, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 254, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 255, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 256, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 257, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 258, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 259, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 260, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 261, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 262, score: 500.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 263, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 264, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 265, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 266, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 267, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 268, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 269, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 270, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 271, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 272, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 273, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 274, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 275, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 276, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 277, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 278, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 279, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 280, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 281, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 282, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 283, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 284, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 285, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 286, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 287, score: 200.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 288, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 289, score: 450.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 290, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 291, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 292, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 293, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 294, score: 450.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 295, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 296, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 297, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 298, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 299, score: 100.0, epsilon: 0.07\n",
            "brrr\n",
            "marking, episode: 300, score: 0.0, mean_score: 74.00, std_score: 104.52\n",
            "episode: 300, score: 0.0, epsilon: 0.07\n",
            "brrr\n",
            "episode: 301, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 302, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 303, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 304, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 305, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 306, score: 300.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 307, score: 350.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 308, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 309, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 310, score: 300.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 311, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 312, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 313, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 314, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 315, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 316, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 317, score: 300.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 318, score: 450.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 319, score: 300.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 320, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 321, score: 200.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 322, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 323, score: 550.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 324, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 325, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 326, score: 250.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 327, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 328, score: 450.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 329, score: 600.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 330, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 331, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 332, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 333, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 334, score: 200.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 335, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 336, score: 350.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 337, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 338, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 339, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 340, score: 550.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 341, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 342, score: 600.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 343, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 344, score: 200.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 345, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 346, score: 350.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 347, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 348, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 349, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 350, score: 250.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 351, score: 200.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 352, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 353, score: 350.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 354, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 355, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 356, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 357, score: 200.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 358, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 359, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 360, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 361, score: 200.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 362, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 363, score: 200.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 364, score: 300.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 365, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 366, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 367, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 368, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 369, score: 200.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 370, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 371, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 372, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 373, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 374, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 375, score: 200.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 376, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 377, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 378, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 379, score: 200.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 380, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 381, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 382, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 383, score: 300.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 384, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 385, score: 200.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 386, score: 200.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 387, score: 250.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 388, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 389, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 390, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 391, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 392, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 393, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 394, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 395, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 396, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 397, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 398, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 399, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "marking, episode: 400, score: 100.0, mean_score: 123.50, std_score: 147.73\n",
            "episode: 400, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 401, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 402, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 403, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 404, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 405, score: 400.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 406, score: 200.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 407, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 408, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 409, score: 300.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 410, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 411, score: 200.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 412, score: 600.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 413, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 414, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 415, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 416, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 417, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 418, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 419, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 420, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 421, score: 200.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 422, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 423, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 424, score: 300.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 425, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 426, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 427, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 428, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 429, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 430, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 431, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 432, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 433, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 434, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 435, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 436, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 437, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 438, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 439, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 440, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 441, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 442, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 443, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 444, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 445, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 446, score: 400.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 447, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 448, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 449, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 450, score: 200.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 451, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 452, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 453, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 454, score: 200.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 455, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 456, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 457, score: 200.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 458, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 459, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 460, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 461, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 462, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 463, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 464, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 465, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 466, score: 200.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 467, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 468, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 469, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 470, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 471, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 472, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 473, score: 200.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 474, score: 200.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 475, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 476, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 477, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 478, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 479, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 480, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 481, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 482, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 483, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 484, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 485, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 486, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 487, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 488, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 489, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 490, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 491, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 492, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 493, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 494, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 495, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 496, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 497, score: 100.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 498, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 499, score: 0.0, epsilon: 0.06\n",
            "brrr\n",
            "marking, episode: 500, score: 200.0, mean_score: 74.00, std_score: 102.59\n",
            "episode: 500, score: 200.0, epsilon: 0.06\n",
            "brrr\n",
            "episode: 501, score: 250.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 502, score: 0.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 503, score: 0.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 504, score: 0.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 505, score: 400.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 506, score: 0.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 507, score: 0.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 508, score: 0.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 509, score: 200.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 510, score: 200.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 511, score: 0.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 512, score: 100.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 513, score: 200.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 514, score: 0.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 515, score: 300.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 516, score: 0.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 517, score: 0.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 518, score: 0.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 519, score: 0.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 520, score: 100.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 521, score: 0.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 522, score: 100.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 523, score: 0.0, epsilon: 0.05\n",
            "brrr\n",
            "episode: 524, score: 200.0, epsilon: 0.05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-f30fb7850f3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Dynamics learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtrain_wm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_wm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Behaviour learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-8b32d82530d5>\u001b[0m in \u001b[0;36mtrain_wm\u001b[0;34m(model, memory, optimizer)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mh_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrs_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone_mask_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mh_lst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxs_lst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-5f6d6bf220c0>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, l)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mxs_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mas_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mas_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mrs_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrs_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mdone_mask_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdone_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}